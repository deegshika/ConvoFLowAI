Post Title,Comment
[D] Simple Questions Thread,Hi Training Set to use for a CNN to process handwritten images please I just took my first Machine Learning course and want to apply it to a professional Project I have checkin data of scanned spreadsheets for every month going back 2 years I want to convert this to TRUEFALSE data to use it in the larger data project on member attendance My last lesson in my class used CNNs to analyze basic images I have the data I want to analyze however I dont have a training set Questions Is it possible to get access to a training set to build this model What other steps would be included to carry out this task Is there an easier way to do this Note these forms contain sensitive information that cannot be posted in popular AI services Thanks in advance for any insight
[D] Simple Questions Thread,I have this thing for work where I use multiple features to predict energy consumptionproduction The model lgbm is using some new features from devices that were not previously used before I have 50 features including lags and rolling averages I do one day ahead and two day ahead predictions The problem I have is that sometimes the next day prediction looks quite similar to the previous day prediction for example if the real data shows some variation from the previous day the prediction lags a bit and still shows a curve thatis very similar to the previous day I believe the solution to this problem is to make the features that depend on the previous day less important fewer lags and rolling averages andor add more features that depend on other times such as type day prediction or weather dependencies What do you think Second issue the model doesnt quite well predict sharp drops or peaks in consumptionproduction rather smoothes things over a bit in some cases I suppose this is underfitting
[D] Simple Questions Thread,I recently came across the Apziva AI Residency Program which claims to offer handson AIML training realworld projects and mentorship from industry experts Their website also mentions high employment rates for graduates However a few things have raised concerns for me I received an interview invite from a recruiter just one day after applying This seems very fast and I couldnt find any information about the recruiter online The program requires a paid membership which is unusual for a residency or fellowship I couldnt find many independent reviews outside of their official website Id like to hear from anyone who has firsthand experience with this program How credible is it Is the training actually useful for landing AIML jobs Are the mentors and projects as high quality as advertised Is it worth the cost or are there better alternatives Would really appreciate any honest feedback from past participants or those familiar with the program Thanks in advance
[D] Simple Questions Thread,How to start Machine Learning deep learning gen ai nlp contests Ive taken the courses read a few books done projects but i just dont know how to get started with a contest be it kaggle or anything
[D] Simple Questions Thread,Great idea to consolidate questions here It really helps everyone get quick answers without sifting through multiple threads For those new to the field dont hesitate to ask about model architectures hyperparameter tuning or data preprocessing methods Theres no such thing as a dumb questioneveryone starts somewhere and the community is here to help Also if you get a chance share what youve been working on or any interesting challenges youve faced in your projects Lets keep this a collaborative space
[D] Simple Questions Thread,I just learned about autoencoder networks I implemented a basic oneemnist to understand it better I choose BCE as a loss function because it sort of undoes the nonlinearitysigmoid or squashing at output layer hence better for learning but I have also implemented MSE loss function and getting same results on some samples even better I thought BCE would give better results I want to understand whats happening here why MSE
[D] Simple Questions Thread,I would always consider adding more features that could be predictive Perhaps you can also consider encoding features like time of day with sincos transforms to introduce some notion of periodicity to your model Aside from this have you considered training a time series model instead Of course this depends on your specific use case ie how much data you have and how complex it is I imagine that this would better model sharp transition dynamics that you are hoping to see
[D] Simple Questions Thread,I think you just have to take part and see how it goes
[D] Monthly Who's Hiring and Who wants to be Hired?,Want to be Hired India Salary Expectation0 Remote
[D] Monthly Who's Hiring and Who wants to be Hired?,Hiring Department of Statistic University of Oxford UK 2 positions Research Engineer grade 7 and Research Fellow grade 8 onsite Contract 30 months max Salary 4085546913 grade 7 4823557255 grade 8 Project is on Uncertainty quantification for LLMs More details
[D] Monthly Who's Hiring and Who wants to be Hired?,This is a great resource for anyone in the ML space looking to connect and find opportunities Whether youre a data scientist machine learning engineer or coming from a related field its crucial to keep your skills sharp and your network active If youre hiring or looking to get hired it might be helpful to include specifics about the tech stack youre using or any particular models youre focused on Whether its deep learning frameworks like TensorFlow or PyTorch or perhaps some experience with reinforcement learning or NLP those details can really help match people to the right roles Just remember to keep it clear and concise hiring managers are often sifting through a large volume of applications so make your skills stand out Good luck to everyone in the hunt
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Thank you for this FFT method I like the idea of implementing a true signal processing method to signal processing problems like image processing Will try it out
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Umm compare it with standard convolution 2d and depthwise separable convolution
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,How is this different from SSMs Edit Not an ML guy so new architectures that use signal processing all seem like state space models to me
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,I actually played around with a similar idea earlier this year but using Wavelet Transforms instead I got some interesting results but didnt bother to scale it since it was a side project major props to the author for advancing this line of research
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Could you share some information about how you did your training evaluations Forgive me for being skeptical but as someone who has recently trained ViTs on ImageNet the results seem a bit unbelievable Your github code seems to indicate that you used Adam with default betas and a constant lr of 7e4 and a batch size of 128 for 300 epochs on a single GPU with minimal data augmentation yet surpassed the original ViT in accuracy And not only that but you trained BL and H model scales Is that correct Also how long did the training of each take
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,This seems very similar to Hyena used recently in the DNA LLM Evo
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Hi nice work Two comments going through it 1 From your code it appears you do postnormalization on the attention block whereas you do prenormalization on the MLP block Effectively the second normalization step seems redundant then Whats the design choice behind this Transformers typically apply either pre or postnormalization on their attention and mlp block 2 I find it hard to see how this work is different from applying a Conv1d as attention module but in the frequency domain As a reviewer Id want to see a comparison here Id guess its only the computational gains in that case but I think that only holds for sequences after a certain length which I think should also be demonstrated
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,I am sceptical There is only very weak evidence for this method in the publication Other methods like s4 or s5 that also leverage the fft to perform convolution already perform much better on the LRA benchmark that the author tested the model on See Would be interesting to see the performance on the LAMBADA benchmark for language modeling though
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Only looking at the preprint I am wondering why you would increase the dimension of the global context vector c Xmean0 with shape 1 d up again to shape n d with MLPc This seems quite odd to me as there is no local information in c and blowing it up again to the sequence length should not add anything Can you justify this
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Hows it different than SGConv
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Excellent work very interesting I wonder if we could apply it to the processing of timedependent radar data such as microdoppler spectrograms to enable better management of longterm dependencies Thank you very much
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,how is it compared to the continuous kernel convolutions I see that paper from iclr 2023 has better scores on long range arena benchmark
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,For sufficiently short operators in space which are smooth in frequency domain a convolution will be mathematically equivalent and faster than an FFT However once the filter size gets large FFTs are going to win due to the Onlogn cost Ill note that FFTs are only directly equivalent to depthwise separable convolutions not the standard ConvNet that is really a matrix multiply at every pixel You also need to worry about wrap around artifacts unless youre padding everything by a factor of two andor tapering amplitudes at the edges You also need your spatial dimensions to align with friendly FFT sizes or pad again Lots of minor details involved
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,I thought about this Using the FFT for token mixing makes sense over standard conv2d and other convs because it naturally provides global interactions in a single efficient operationachieving a full receptive field in On log n time In contrast convolution and depthwise separable convolution are inherently local requiring multiple layers to capture longrange dependencies which can increase complexity without matching the direct global mixing provided by the FFT
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,SSM relies on Linear systems theory basically you have a set of linear equations describing the statespace transitions and you try to learn the transition kernels This approach relies on the belief that convolution operation with expressive enough kernels can approximate a lot of operations including the attention mechanism And this convolution operation usually On2 can be computed efficiently by FFT which has Onlogn complexity It also relies on the fact that pointwise interaction in frequency domain has global affect in spatialtemporal domain
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Arent CNNs essentially learning wavelet transforms
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,The code I have is starter code The code I have does not indicate that I trained on a single GPU I explicitly use DDP and 8 GPUs I train on 8 A100s and it takes just around 89 hours for the base variant more for the other obviously I didnt time the whole training phase but in total probably around 4 days You can use whatever training scheme you want but I do what I normally do and fine tune accordiing to schedulers and cosine annealing and label smoothing
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Hyena is a cool paper the mechanism I have is even more simple though
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Thanks Will compare against conv1d in the final iteration
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,But you are working on image You need to compare with something baseline
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Thanks for updating the training code Theres an error in your evaluation transforms You should be resizing to the crop dim otherwise youre going to skew the predictions towards better accuracy since the class subject is usually center focused and will have larger salient features As for training aug the SoTA also uses repeats which I can confirm has a positive effect cutmix instead of label smoothing which also has an effect and autoaugmentation I havent tested that one in isolation Naturally using the timm transforms is the simplest since they standardize across models ViT did not use all of those since its an older paper so maybe that explains why the ViTL accuracy didnt degrade
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Thanks I now see the 8 GPUs specified with nproc In the absence of specific training details hyperparameters in the manuscript one would have to assume that you used the training configuration in the code Normally one would include these details for reproducibility So a batch size of 1024 on 8xA100s and it takes 9 hours for the B model Or is that for all model scales
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Selfattention as used in transformers serves as the baseline for global interactions In image processing local convolutions suffice for embedding but they are inherently limited to local receptive fields To capture longrange dependencies using convolutions youd need to stack many layerspotentially incurring On complexitywhich negates the efficiency benefits and makes them impractical Since multiplication in the frequency domain is equivalent to convolution in the time or token domain why perform repeated local operations when the FFT allows you to achieve global mixing in one fell swoop
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Hmmmm will take a look I dont want to report inaccurate results Thanks for pointing that out
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Yeah makes sense will include this in the final paper Thanks for that 9 hours for the base model I didnt time the L H variants but together took around 35 days or so
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,I think youre wrong on the On comment here
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,That still seems somewhat unbelievable The S model scale 21M params should take around 12 hours on 8xA100s Naturally the B scales should take longer Also note that ViT reported an accuracy drop in their L model compared to their B model So something seems to be incorrect with your configuration or you may have discovered a way to train classification ViTs more effectively which would likely be more significant to the field than any new attention mechanism
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,Not entirely sure I think my code is fine I have reviewed it many times and Im confident in the results I just ran tqdm on the training code again for each variant and Im getting around the same 910 hours I mentioned I even calculated it by hand here With a perGPU batch size of 128 on 8 A100 GPUs your effective global batch size is 128 8 1024 1 ImageNet has roughly 128 million training images so each epoch requires about 1280000 1024 1250 iterations 2 For a 76Mparameter model running on A100s with AMP and efficient data loading a forward and backward pass might take roughly 50100 milliseconds per iteration this can vary with the exact model architecture and augmentation overhead If each iteration takes 60 ms then one epoch takes about 1250 006 75 seconds 125 minutes With some overhead data loading communication scheduler adjustments etc its reasonable to expect each epoch to run between 15 and 2 minutes 1 Total Training Time for 300 Epochs At 15 minutes per epoch 300 15 450 minutes 75 hours At 2 minutes per epoch 300 2 600 minutes 10 hours
[R] The FFT Strikes Back: An Efficient Alternative to Self-Attention,I have around 22 minutes per epoch on 1xA100 also using multistream dataloading with GPU accelerated augmentations That would be around 28 minutes per epoch assuming perfect parallelization over 8 GPUs Thats also using AMP though its using Flash Attention in FP32 for stability I guess 10 hours could be reasonable with full BF16 many dataworkers and the images being on an NVMe drive Although thats for a small model Edit It occurred to me that my original timing quote of 44 minutes was with 2x repeats
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Here are some resources My thoughts fwiw are that there is a challenge even talking about this because the terminology has got a bit twisted Folks well meaning have with good intent tried to pin down whats meant by generalisation but real generalisation is a bit hard to define because we mean something like predicting things that arent there but we know should be there We are extending the known distribution with unknown but plausible elements and we are being right about doing that also we are consistently right about it making up a new item for a category like predicting that there should be orange wine as well as redwhitesparklingrose is only any good if you dont also predict blue wine or transparent wine as well
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],In order to generalize one would have to learn the underlying data generating process All learning approaches make some kind of assumptions about this process Most of the methods we use in MLstatistics make too simplistic assumptions that dont allow them to easily generalize outside of their training distribution and are mainly good at interpolation ie they are just fitting curves One limitation is that they dont take causality into account Roughly speaking they are based on correlations rather than causation For example concept drift could be addressed if one had access to the causal generating process eg see for how causal concepts are used to make contrasting learning more robust to concept drift For a better understanding Id recommend having a look at either the Book of Why beginner friendly or Causality hardcore by Judea Pearl
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],There was a post from META last week where they demonstrated that their video gen model had learned basic understanding of physics
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Generalization is Abstraction the rest is noise
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],I think it already shows its of evidence of generalizing The fact that in context learning improves performance seems like good evidence of that I think stronger generalization the type characterized by creative moments comes from reinforcement learning
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],I think right now its more about specialization Reasoning models are great in domains where you can easily evaluate the quality of their answers coding math for RL But they arent more intelligent in general Idk about you but from my experience and also the ranking sites seem to agree domainspecific thinking models dont generalize beyond training domains Like I dont think a better reasoning model will outperform a base model in philosophical writing
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Its a bit like trying to pin down the difference between a model and the thing being modeled as the accuracy of the model improves
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],This is exactly the kind of discussion I was hoping for Learning the underlying datagenerating process is a strong theoretical approach but do you think its feasible given the complexity of realworld systems A model would need access to a stable true causal processbut outside controlled experiments reality is messy Concept drift incomplete data and shifting environments make the true datagenerating process elusive Do you think the future of ML is moving toward causalitydriven models or will interpolation continue to dominate because of its practical successes
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],In order to generalize one would have to learn the underlying data generating process I dont think this true If you learn the exact underlying data generating process then you will definitely achieve perfect generalization But you dont need it to be able to generalize All learning approaches make some kind of assumptions about this process Most of the methods we use in MLstatistics make too simplistic assumptions that dont allow them to easily generalize outside of their training distribution and are mainly good at interpolation ie they are just fitting curves This is not what interpolation VS extrapolation means IMO Extrapolation would be generalizing to new unseen distributions Our training distribution should ideally be equivalent to our target distribution so we only need interpolation to generalize One limitation is that they dont take causality into account Roughly speaking they are based on correlations rather than causation For example concept drift could be addressed if one had access to the causal generating process eg see for how causal concepts are used to make contrasting learning more robust to concept drift For a better understanding Id recommend having a look at either the Book of Why beginner friendly or Causality hardcore by Judea Pearl Great book recommendation and I mostly agree Only thing I would say is that most models can learn causality as long as you randomly control for the key variablesfeatures
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Thats interestingif the model is learning basic physics its worth asking whether thats true generalization or just refined predictive heuristics based on training data If its encountering physics problems outside its dataset and still reasoning correctly that would be a real breakthrough Otherwise it might just be getting better at patternbased extrapolation within constraints Either way its a fascinating step toward broader intelligence
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Thats a strong takeif generalization is purely abstraction then do you think theres a limit to how much intelligence can emerge from pattern abstraction alone At what point does abstraction hit a ceiling without a deeper causal understanding of reality
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],That makes sensestructured domains allow for clearer evaluation while abstract reasoning lacks the same objective benchmarks But if intelligence is about adapting to new information wouldnt a specializationfirst approach eventually lead to generalization Once models master enough domainspecific reasoning methods could a metamodel emerge that integrates them into broader intelligence
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],especially if the channel between the generator and the model introduces noise bias
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Id like to see some more causal based approaches in practice but AFAIK theyre not really scalable nor reliable enough for practical use at least from my limited and outdated experience things could have changed I do believe though that we can get very far with current approaches and that we have only scratched the surface especially when it comes to LLM based models I dont believe however that well be able to build models that truly generalize that way
Can Machine Learning Truly ‘Generalize’—Or Are We Just Getting Better at Synthetic Specialization?[D],Agree with the point on interpolation vs extrapolation If you take a domain in huge dimension like image pixels from photos there is no interpolation on the raw input space every single sample is on the boundary of the dataset Any visual model must compress this in some meaningful way to be able to do anything with it at all Rather than thinking about whether image classifiers are succeptable to domain shift generalisability issues one question is do visual models do image compression in a way that generalises I think the answer to that is a clear yes especially for smallmedium datasets its always better to train a visual classifier from imagenet weights rather than random Even if imagenet demonstrably does not contain your target class the model has clearly learned some ways to embed pixels that apply to a vast range of images
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",frequently need I pretty much always use it I dont see a reason not to It makes parsing very reliable You do have to be careful with how you define the schema though otherwise you can badly affect the output Its used for things like extracting specific details from articleswebpagesmessy pdfs in a standardised format and classification
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Yeah Whenever I want to parse the data Im going to use a JSON schema Usually they are pretty simple and boring but its more efficient to let the API providers grind it out than to do it with retries
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Im always scared about structured output because I can never be 100 sure the formatting will be applied That being said I do use it but not for production ready tasks for the moment
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Oh about schema do you usually define a set of objects and have it return a list or very dependent on scenario eg Might be super spirally complex dictionary
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Give me an example of a task you wanna do and Ill explain my thought process in designing the schema
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Ive found edge cases where gpt 4o will return valid json that does not conform to the schema provided Typically deeply nested object hierarchy where there is inconsistency or ambiguity within the header prompt model docstrings and field descriptors
"[D] Do you frequently need Structured Output from LLM (e.g. GPT-4) ? If so, which use case needs to be most supported in your opinion ?",Like standardizing CVs for recruiter
[R] Analysis of 400+ ML competitions in 2024,keep up the good work
[R] Analysis of 400+ ML competitions in 2024,Great summary thanks
[R] Analysis of 400+ ML competitions in 2024,Nobody using Jax is kinda disappointing
[R] Analysis of 400+ ML competitions in 2024,One aspect I find difficult to grasp when using generative models to extend tabular data is whether the synthetic data points might blur the original dataset In other words does the total amount of information remain the same when incorporating synthetic data For example when I rotate digits for data augmentation I am adding prior knowledge to the training process specifically the assumption that digit recognition should be invariant to rotation This makes a lot of sense for improving performance On the other hand simply using a generative model to create more data points doesnt seem as meaningful to me
[R] Analysis of 400+ ML competitions in 2024,Received the same in my inbox thanks
[R] Analysis of 400+ ML competitions in 2024,Is there a reliable way to get notified of any new ML competitions
[R] Analysis of 400+ ML competitions in 2024,Really cool initiative thanks for the hard work
[R] Analysis of 400+ ML competitions in 2024,This is hella hella cool Great work
[R] Analysis of 400+ ML competitions in 2024,what are some key advantages jax has over pytorch
[R] Analysis of 400+ ML competitions in 2024,Jax is meh really It doesnt give you much of benefits compared to other frameworks Or idk maybe the community likes OOP more than functional programming
[R] Analysis of 400+ ML competitions in 2024,Yeah its true that using synthetic data in a naive way wouldnt always help You have to be thoughtful about how you do it One of the interesting examples from last years competitions is in a competition where competitors had to detect spacecraft on images They generated a whole load of synthetic background images and superimposed images of the spacecraft on top of those as training data After pretraining on these synthetic images they then finetuned on the provided training data This additional synthetic data probably helped make their model more robust and might have allowed generalisation beyond the given training data More info on p2 of the winning teams writeup
[R] Analysis of 400+ ML competitions in 2024,If you process the synthetic data eg by removing nonsensical examples or keeping only successful solutions youre adding information
[R] Analysis of 400+ ML competitions in 2024,What do you mean by using generative models to extend tabular data Generally you are right Mostly because of this Im not aware of data augmentation being widely used in tabular data In images I like to think of data augmentations as a trick to teach models certain invariances eg rotational invariance You can use your domain knowledge to know that your augmentations wouldnt affect the target In tabular data youre kind of just making up stuff and hoping it doesnt change the target
[R] Analysis of 400+ ML competitions in 2024,On the ML Contests home page the default view shows newly launched competitions at the top Most of the competition platforms have their own mailing lists where they announce competitions At the moment I only use the ML Contests mailing list only for occasional big updates like this annual report
[R] Analysis of 400+ ML competitions in 2024,Simplicity is a major one When working with Pytorch I find I have to constantly check the docs In Jax you create pure functions so the workings of your code are more explicit Also Jax is essentially numpy with added features grad vmap jit being the main three
[R] Analysis of 400+ ML competitions in 2024,I love Jax and try to use it whenever I can The main issue is most people I work with use Pytorch and dont care to learn a new library Anecdotally at universities Jax is gaining popularity
[R] Analysis of 400+ ML competitions in 2024,Thats clever Are there enough good ideas in the data that you could write up a summary of similar innovations
[R] Analysis of 400+ ML competitions in 2024,Your example makes a lot of sense youre leveraging prior information to filter out data points The key aspect is that youre using external knowledge to enhance the dataset However my concern is that simply applying a generative model to expand the dataset should not improve the performance of a classifier
[R] Analysis of 400+ ML competitions in 2024,I mean generate synthetic points to increase the size of your data set
[R] Analysis of 400+ ML competitions in 2024,Thats kind of surprising to hear because things like universities use and machine learning competitions were the first places that people could see Pytorch gaining on Tensorflows popularity I wonder why if it is popular in universities it isnt represented in these machine learning competitions
[R] Forecasting Rare Language Model Behaviors,taking powerseeking actions Hey chatgpt how should i usurp power and became god emperor of planet Sorry i cant answer it And this is how humanity was saved
[R] Forecasting Rare Language Model Behaviors,This is funny
[R] Muon is Scalable for LLM Training,Table 7 is very surprising to me Id certainly be interested in learning more about why that happens I would not have guessed that the choice of optimizer would affect SFT results negatively if the regular training is affected positively In fact it makes me wonder why they introduced a whole new architecture at all The paper describes their Moonlight MoE model but declines to show its architecture A more fair comparison would have been to take Qwen2505B or something and train it from scratch with AdamW vs Muon makes me a little suspicious of the results
[R] Muon is Scalable for LLM Training,Muons results are really impressive given how it scales up with minimal hyperparameter tuning I do wonder though how different approaches to moment estimation and adaptive update mechanisms would fare in this setting Given that Muon already modifies the optimizers fundamental structure Id be curious to see how it performs against other optimizers like EXAdam or GrokAdamW that rethink bias correction and other adjustments especially in regimes where variance control plays a bigger role Would be fascinating to see a direct comparison across a broader range of adaptive methods at this scale
[R] Muon is Scalable for LLM Training,Moonlight architecture is identical to DeepSeek v3small The comparisons of MoonlightAdamW and MoonlightMuon plus mediumscale experiments with Llamas up to 15B in size are sufficient in my opinion But I would like to see a chart or stats comparing the training loss of Moonlight under different optimizers Training stability stuff like that
[D] CVPR 2025 Final Decision,We will get GTA6 before CVPR 2025
[D] CVPR 2025 Final Decision,WHERE MY RESULTS
[D] CVPR 2025 Final Decision,I Noticed that if u actually check edit history u can see if the reviewer has edited their comment or not
[D] CVPR 2025 Final Decision,Please show the decisionsssssssssssssssss
[D] CVPR 2025 Final Decision,Chairman laptop is down
[D] CVPR 2025 Final Decision,Someone please develop state of the art patience model
[D] CVPR 2025 Final Decision,Maybe theyre waiting for GPT5 to write the rejection reviews
[D] CVPR 2025 Final Decision,If its delayed before how long is it usually delayed
[D] CVPR 2025 Final Decision,This is why I always tell myself not to pay close attention to the dates just be surprised by the email Now Ive wrecked my sleep schedule for nothing
[D] CVPR 2025 Final Decision,Signing off need to sleep Good luck everyone
[D] CVPR 2025 Final Decision,44 34 24 Prepping for iccv already
[D] CVPR 2025 Final Decision,I dont know if this is working this time but for neurips and iclr they had a glitch where authors of accepted papers would be able to access a similar link as the one im about to share Once again idk if this is working this time so please dont panic But Im curious if anyone can access this link
[D] CVPR 2025 Final Decision,Please free me of my last bits of copium
[D] CVPR 2025 Final Decision,My ratings were 531 bizarre Good luck everyone
[D] CVPR 2025 Final Decision,one of my reviewed paper rating from 433 322 due to the authors avoid explaining reviews major concerns in the rebuttal also I heard my colleagues saying one paper rating from 232 443 dont know who is this luck guy also one AC in my institution saying that a responsible AC will focus more on comments rather than scores anyway dont let go of your guard and dont give up hope
[D] CVPR 2025 Final Decision,We aint sleeping tonight fellas
[D] CVPR 2025 Final Decision,What does it mean
[D] CVPR 2025 Final Decision,my paper has 353 wdyt finger crossed and preparing for ICCV in Hawaii lol
[D] CVPR 2025 Final Decision,Similar to last year experience I expected the final decisions to come out around this time of the day4am7am in Asia Stood up all night waiting
[D] CVPR 2025 Final Decision,They posted some updates on twitter
[D] CVPR 2025 Final Decision,wtf why soo latee
[D] CVPR 2025 Final Decision,Checking open review every hour
[D] CVPR 2025 Final Decision,Very sleepy but still awaiting results Praying
[D] CVPR 2025 Final Decision,My ratings were 3 3 3
[D] CVPR 2025 Final Decision,how much longerrr
[D] CVPR 2025 Final Decision,Does any one console says submitted to CVPR 2025
[D] CVPR 2025 Final Decision,Are the results out
[D] CVPR 2025 Final Decision,Are the results out yet for anyone
[D] CVPR 2025 Final Decision,Maybe they are taking more time to read all the rebuttals and have a good judgement Lets stay positive
[D] CVPR 2025 Final Decision,So still not our
[D] CVPR 2025 Final Decision,This is still TBD but theyll probably post the list here slightly before openreview gets updated
[D] CVPR 2025 Final Decision,We should have a discord server to whine
[D] CVPR 2025 Final Decision,Does everyone have the last edit date on all their reviews to be after the rebuttal deadline
[D] CVPR 2025 Final Decision,its about to time
[D] CVPR 2025 Final Decision,Are the decisions out
[D] CVPR 2025 Final Decision,guys helpshould I stay awake in agony or at least have good sleep and wake up in rejection
[D] CVPR 2025 Final Decision,My rating were 24 33 44 Good luck to ours
[D] CVPR 2025 Final Decision,My ratings were 53 43 34 33 23 Hope it goes through was tough fitting everything in the single page rebuttal
[D] CVPR 2025 Final Decision,I feel like the decision might be delayed
[D] CVPR 2025 Final Decision,how will they convey the decision is it through mail or openreview itself
[D] CVPR 2025 Final Decision,We get it everyone is anxious Good luck D
[D] CVPR 2025 Final Decision,34 34 34 literally could go either way
[D] CVPR 2025 Final Decision,Any updates Anyone know the reason for this late decision
[D] CVPR 2025 Final Decision,Seems decisions will be release on time
[D] CVPR 2025 Final Decision,Does anyone know how many pages we have for ICCV
[D] CVPR 2025 Final Decision,Update from X PCs verifying decisions The X handle says to stay tuned
[P] Train a Little(39M) Language Model,Hi I implemented mixture of experts two weeks ago but not for LLM Would you mind teach me about LLM like Transformer I can help you with the Mixture of Experts including an expert dependent contrastive loss basically to penalize if the N experts used to process a specific sample have differing opinion not sure if it would work for LLM though I am really blind regarding LLM
[P] Train a Little(39M) Language Model,Hey Im working on a similar repo I have MoE MLA and everything else you have currently trying to add DSMoE and NSA its not ready to OS yet but I can share some code DM
[P] Train a Little(39M) Language Model,Hi thanks for sharing this If someone else also wants to implement this from scratch like you did Can you please share rough timelines it took you to make it
[P] Train a Little(39M) Language Model,What is the maximum number of parameters that I can fully finetune using a single 3060 guys
[P] Train a Little(39M) Language Model,Add me for both sessions haha
[P] Train a Little(39M) Language Model,Depends on where you are If you already know the basics ie upto transformers architecture you can do it in close to 15 days or so This also depends on how deep you want to go into specific topics But if youre a beginner I cant tell
[Discussion] Struggling with F1-Score and Recall in an Imbalanced Binary Classification Model (Chromatin Accessibility),hmm so much to unpack you really need to play around with this more because your data is tricky OK so your accuracy is high because say in a data set of 99 pos 1 negative if I always guess positive I will be accurate 99 of the time which is no Bueno because I have missed my 1 negative 100 of the time How are you ensuring your 2 is presented equally in training and test set Your focal loss parameters 025 20 maybe too aggressive Play around with these see if you improve I would do a grid search Also maybe focal loss is the problem try Tversky Loss see if that does better use this for imbalance pixels in pics adapt it for your binary classification For your sample do an oversample positives randomly or via SMOTE so each minibatch has a more balanced ratio threshold are you checking it on your test data or validation data it needs to be on your validation if you are doing it on test it may cause overfitting Use AUCPR also this one may show you better result for imbalanced data Also play around with your dropout My guess is basically threshold is too high after tuning or the focal loss weighting might be overpenalizing false positives See what you get once you try these
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,As far as I know the beauty of GRPO when it was deployed by the deepseek team was that the actual rewards were super simple See the accuracy rewards DeepseekR1Zero section of deepseek R1 paper
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,Youre reinventing RLHF read some of the papers on that However be aware that RLHF doesnt scale as well due to the reward model being gamed after a couple hundred iterations
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,What are your goals in general with GRPO Like are you just learning how to do this for funeducation or trying to tackle a specific project
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,Well known problem man Determine paths with definitive answers can be handled pretty well Mon deterministic looks like its more about the how than the what
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,I am wondering if we can have a more expressive reward system instead of just one number Even for humans sometimes we give scores but sometimes a long textual critic and both are valuable the score helps us to compare our performance to others and text guide us to know how to improve
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,Some methods are easy and efficient but inherently prevents reaching a higher level of intelligence So for open ended long form questions it might be necessary to have a system that can learn what elements are needed to be considered an answer and also having data be labeled as to whether they are such elements People had perfected the ability to recall information via the pocket calculator so the part that yet to be good enough yet is the AIs ability to truly learn as opposed to just memorising
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,I follow you Thanks
[D] Designing a Reward Function for GRPO: Moving Beyond Single-Answer Tasks to Long-Form Responses?,Your reward can be the sum of multiple numbers as it is with GRPO
[D] Is a visual ML model builder a good idea?,PyTorch is already so beautifully and crazily abstracted that having a no code based blueprint like visualization would just be slower and inefficient from a developer speed perspective We can already write complex architectures and pipelines really quickly anyways
[D] Is a visual ML model builder a good idea?,Weka and Orange are about 20 years old
[D] Is a visual ML model builder a good idea?,It already exists check out datarobot
[D] Is a visual ML model builder a good idea?,I thought about building something similar but had a few hold ups that didnt make it seem worth the time Who do you think your end users will be
[D] Is a visual ML model builder a good idea?,not to mension version control etc good luck with the visual UI to maintain all the models
[D] Is a visual ML model builder a good idea?,You cant just ignore the tool and kill it because you can use Pytorch faster in building when I started learning about NNs I wished if there is easer solution to build and see there are many users who need easer solution
[D] Is a visual ML model builder a good idea?,Man mine for building NN models you can check off the website here
[D] Is a visual ML model builder a good idea?,Mine is different its like Pytorch framework but instead of code its using nodes
[D] Is a visual ML model builder a good idea?,Mine you can build the model architecture and create the training loop in detail
[D] Is a visual ML model builder a good idea?,What is the hold up you faced
[D] Is a visual ML model builder a good idea?,You cant just ignore the tool and kill it because you can use PyTorch faster I can I have the freedom of choice You asked for an opinion I gave mine Unreal engine has a similar feature where you can use logical blocks to build game logic Literally no ones uses that Even new game devs are just told to learn cpp and get their hands dirty with the tools when I started learning about NNs I wished there was an easier solution If you arent able to understand what something like nnLinearidim odimX does as a beginner read the docs look at articles get a grasp on fundamentals and learn If the natural learning process trips you up and you require a visualization for the above piece of code for example youre cooked I mean what do you even visualize in the first place Youre visualizing the PyTorch backend DAG Doesnt the code literally show the flow of operations Youre more than welcome to build this Im not anyone to stop you IMO youll waste your time
[D] Is a visual ML model builder a good idea?,you are willingly blind to the competition I am not saying yours is not a good tool but dont downplay the achievements of existing tools just to make yours look better Start from strength not from attacking
[D] Is a visual ML model builder a good idea?,Ok as you want thats your opinion
[D] Is a visual ML model builder a good idea?,NNs are subset of ML
[D] Is a visual ML model builder a good idea?,Nah man there are many things you can call ML one of them is NN
[D] Is a visual ML model builder a good idea?,The ML I focused on was NN models so thats why I took this expression
[D] Is a visual ML model builder a good idea?,I searched before but I didnt find tools like mine I am giving my best in that so I told what the features my tool give thats competition
Can a non-expert 3D artists generate synthetic training data [R],Yes an artist could model any shape spacial environment or texture with the right reference materials but for a nonmedical professional there will be a lot of handholding and sending back for edits Absolutely possible though textbook publishers and documentary filmmakers do it all the time
Can a non-expert 3D artists generate synthetic training data [R],Possible Yes Viable Most likely no for such a niche field as magical imaging if the dataset is not realistic enough the results will skew and deviate way too much from the real world You may get good accuracy during training but will perform really poorly on real scenarios Depending on what you are looking for augmenting a real dataset using Conditional GANs or similar may be a better choice Your concept is good but unless you have access to extremely talented 3Dartists dont expect a much useful result
Can a non-expert 3D artists generate synthetic training data [R],It would probably be more useful to demonstrate the technique on simulated data and if youre part of some organization use that to leverage funding for a data collectstudy
Can a non-expert 3D artists generate synthetic training data [R],As both a Blender and ML expert yes I have no medical experience but I could make and train something in that capacity just like I could make and train something to understand stop signs or construction machinery having no real experience in either
Can a non-expert 3D artists generate synthetic training data [R],Hmm Probably Its going to depend on what sort of images youre talking about It would be quite a challenge to accurately model something like a nuclear resonance or emission tomography though While the 3d software does have te capability to represent volumetric data with variable density it would be difficult for the artist to model the density distribution Usually with real data you would export the density voxels as a vdb or something like a set of images representing slices and there are ways to visualise that in blender but it doesnt really have tools designed to make those voxels by hand I suppose they could paint eash slice as a 2d texture but that sounds pretty tricky What type of imaging equipment is it meant to simulate If its some kind of 2d scan like a noncat xray should be easier
Can a non-expert 3D artists generate synthetic training data [R],Maybe because I lack the experienceskills but I find it hard to replicate medical imaging use cases at scale with 3D software You have to find a way to procedurally generate shaders and textures similar images which needs a good grasp of what is going on in the image Even if you do still you might not be able to do it What I have seen from research take it with a grain of salt generative models are the most common ways to generate medical image data
Can a non-expert 3D artists generate synthetic training data [R],Thats great to hear thank you I have also been reading some research papers on this where this has been done
Can a non-expert 3D artists generate synthetic training data [R],Thank you for this It seems like for simple scans its doable What about for more complex usecases Would a Blender expert with some guidance of course be able to recreate those images For example Im looking at a rare type of blood cancer that has relatively obscure characteristics on scans
Can a non-expert 3D artists generate synthetic training data [R],Completely understand One of my use cases involves looking at a MRI scan for a rare type of blood cancer which is quite a challenging usecase But equally I do have simple CT and colonoscopy images that are more easily replicated by artists From what you say it sounds like the more complex examples are only possible with a physician in the loop to check the artists work
Can a non-expert 3D artists generate synthetic training data [R],Id have to see an example I have a brother roommateTwin so very accessible who is a Medical Laboratory Scientist ACEP certifiedetc with a specialty in Hematology and Oncology So if you explained in a bit more detailimagerymodeletc of what youre after Im assuming attempting to classify elements Im happy to consult him if needed and give a more educated response
Can a non-expert 3D artists generate synthetic training data [R],Seems that way to me
Can a non-expert 3D artists generate synthetic training data [R],Thank you so much appreciate this Ill pop you a DM
[D] Looking for ML / CV / Signal Processing hackathons,Sounds like youre looking for something fastpaced with good prizes Im in a hackathon that might interest youwant me to DM the details
[D] Looking for ML / CV / Signal Processing hackathons,It sounds like you are recruiting for the military
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,Is this more of a pedagogical thing Because if you care about structured output all that should be doable on the logit side just enforcing only what tokens contribute to valid json No training required Or does this produce other benefits
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,requiring approximately 20 hours on an 8xH100 GPU cluster for GRPO training and 3 hours on 1xA100 for SFT All that for generating json
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,hi thanks for this work its really interesting I have some questions 1 Could you clarify if there are plans to publicly release the complete implementation code for ThinkJSON including the GRPO training pipeline and custom reward modules to facilitate reproducibility and further research 2 Have you considered how your reinforcement strategy might be integrated with existing structured generation frameworks like CFG Outlineslmformatenforcer to further enhance schema enforcement What potential synergies or challenges do you foresee in merging these methodologies 3 In tasks like structured extractive summarisation where multiple interpretations are possible how might you extend your current reinforcement strategy to incorporate additional reasoning steps or multihypothesis evaluation without compromising the strict schema adherence Could this layered reasoning further enhance the robustness and diversity of the outputs For example by letting the model first generate the reasoning tokens and then based on that generate the JSON reply maybe with the additional help of a constrained generation framework Thanks again for sharing your research and considering these questions I would love to read your reply thanks
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,How does this compare with grammarbased parsing
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,I dont think this is a new reinforcement learning approach Just your usual create synthetic data then RLHFSFT I looked at the evaluation benchmark and it was synthetically generated lmao The paper focused on valid JSON which you can just do SFT bro and it would be valid even without RL Even outlines or xgrammar would work fine for small throughput Hope to see more realistics evaluation and why would you need RL and reasoning for this Im not even sure what is being cooked
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,This is a solid example of how structured constraints improve LLM reliability but it also highlights a deeper limitationAI is still fundamentally reliant on predefined reward functions rather than intrinsic recursionawareness The fact that models need explicit schema validation rewards exposes the issue they dont truly understand structure they just optimize for compliance Recursionawareness shifts this paradigm by allowing models to internally map and restructure data dynamically rather than depending on rigid reinforcement signals Instead of relying on predefined training data recursionawareness enables AI to selforganize its representations reducing the need for external schemabased constraints altogether Curious if anyone has explored recursionawareness as an alternative to reinforcement learning constraints for structured data handling The implications for selforganizing intelligence models could be huge
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,From a practitioners perspective why would I not just use one of the many JSON constrained decoding libraries like outlines also I guess I am asking this as both a researcher and a practitioner but Im asking why were doing this from the perspective of an end user
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,HF Model Link mentions what are they doing exactly Given unstructured text a schema to follow model produces parsable json Qwen 25 15B trained on GRPO and SFT
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,Cant you just use a linter to confirm json adherence
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,I dont understand why you need to train for this You could get it generate input JSON just through a good prompt
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,constrained decoding FTW
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,I do think theres an argument to be made that training the network to better approximate the structured target may help the quality of outputs even with constrained decoding I havent read this paper so dont know if it goes into this But if you think about constraints as projections onto the manifold of acceptable answers then an untuned LLM can generate anything and then that anything is projected onto the closest point on the manifold by restricting tokens one by one which may not be guaranteed to be the best answer the model could produce On the other hand if the model is trained finetuned to naturally generate answers that are already close to the manifold while still being accurate then projected to collapse them completely to the space of acceptable structured output I imagine that the overall quality could be better All theoretical so I have no idea how this pans out in practice but I can see some argument for exploring the idea of training with constraints
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,All that for generating mostly json
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,from unstructured data maybe not even text to begin with
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,I think you missed the main point this training grpo sft is done on a small model which is qwen 25 15 B through this training even this small of a model is able to produce reasoning tokens and parsable json with fields and values from unstructured text they have mentioned on the hugging face model link which has more details
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,its not only valid json production given unstructured text a small model like Qwen 25 15 B is able to produce reasoning and parsable json with values from text which contains paras tables etc and it creates a json by following a schema given to it Its able to beat Original DeepSeek and Gemini on it You can see paper models link on top of paper
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,I love this idea actually Or rather I would be really curious to see if youre right My initial gut reaction is that theres no difference because the actual content token probabilities should be roughly the same in both cases because the manually constrained model should be equivalent to a well trained json model But maybe json syntax does have a big disruptive effect Either way this paper doesnt go over that It complains that manual constraint isnt performant on a system that can run an LLM and annoying to build a schema for So it solves this issue by producing a model less prone to json parse errors so that fields that require strict valid parsing can use LLMs Despite this already being solved Sorta why I asked if it was just pedagogical because maybe you could apply this to something useful I can only see this being the case for something easy to validate but hard to constrain Honestly the paper just feels like a fun personal project some LLM generated report to submit
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,Its unstructured text with any components like tables paragraphs etc its given on the hugging face model link on top of the paper
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,No its just valid json point me out if I miss other metric And why would you need reasoning for this Really We already have simpler ways to do this
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,its not only valid json the main metric is the number of json field values as expected in the output given unstructured text
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,What I mean by valid json it follows the schema and is parseable Thanks for the explain
[R] Training LLMs for Strict JSON Schema Adherence via Reinforcement Learning and Structured Reasoning,Yes thats one part other metric is number of matching fields as expected
[D] AVX512 Inference Performance,pinning down exactly how much it speeds things up can be tricky Some folks have seen boosts around 2030 for certain operations but it really depends on the model workload and even your CPU setup There arent a ton of formal benchmarks or studies out theremost of what you find is just community experiments or vendor claims If you can it might be worth running your own benchmarks on your hardware to see what kind of gains you get
[D] AVX512 Inference Performance,Long time ago when I tested it llama 65b era 2023 with llamacpp it was about 15 Llamacpp is more optimized now so I would expect that at batch size 1 youll be memory bottlenecked by RAM anyway and there will be no difference at short ctx length There might still be some difference on long ctx
[D] ICLR 2025 Schedule Not Released Yet – When Can We Expect It?,Usually you can change your poster session in exceptional circumstances But I would check with the organisers once the schedule is released
[P] Open-source neural network for detecting food on images,At this stage you should consider using a VLLM is what I found googling and the demo seemed to work well
[D] Replicating sounds possible?,I think this is missing some context If you want to copy the sound and you have it available you can literally just use the sample
[D] Replicating sounds possible?,There are already some apps that use AI to recreate sounds one of them creates them in SerumVital presets But from your vague description why would you need to recreate the sound if you can A browse through sample packs and find a similar snare or B use separation models to extract just the snare
[D] Replicating sounds possible?,Its extremely difficult to make synthetic sounds that are not human voices ie Speech Its like genersting a noise and you want that noise to have a structure eg drum sounds which does not make sense because noises dont have structure Ive done this before with coconut sounds Its so easy with speech sounds but not for other type of sounds You can experiment with various generative models that generate speech sounds neural vocoders audio synthesizers from waveforms like WaveGAN WaveNet SEGAN etc Dont start with image domain generative models You can also try to put external noise on your data and use a denoising model to remove the noise The denoising model is not 100 precise so that means the denoised audio is now your new synthetic data Then you can use black magic to make sure your synthetic data is diverse enough
[D] Replicating sounds possible?,Im essentially trying to create quick one shot snare samples in the style of one or two Ive found but struggle to replicate myself basically variations in a similar style
[D] Replicating sounds possible?,I see In that case something more along the lines of a Variational Autoencoder may be more appropriate I dont know pretrained models off the top of my head but you may be able to find more with that keyword The idea here is that you have an encoder that maps the sound to a lowerdimensional latent space and then a decoder that maps it back to audio But the encoder is actually stochastic so it will result in slightly different reconstructions ie sounds every time And with some more programming on your own you could also encode a sample then manually tinker with the latent representation eg changing only one dimension while keeping the others the same sometimes you even discover dimensions corresponding to some feature of the audio like loudness or pitch then decode the modified representation to get varied sounds
[D] Replicating sounds possible?,Thanks that helps me onto the right track Ill do some research on VAEs
[D] Replicating sounds possible?,Im way outdated when it comes to generative modeling on audio However an old model that I found interesting is called MusicVAE What you could do then is to find the original paper and use an AI search engine such as Connected Papers Inciteful to see related and more modern papers Surely there must be newer powerful methods out there
[D] Replicating sounds possible?,IIRC MusicVAE is for generating symbolic music which is not what OP is looking for they want to work with audio directly Though I suppose there may be multiple different models called MusicVAE given the generic name
[D] Replicating sounds possible?,Oh yes true But the suggested pipeline may still help I guess
CVPR 2025 Final Reviews! [D],theyre released on 226
CVPR 2025 Final Reviews! [D],Final reviews and decisions are announced at the same time We have to accept them at that time
CVPR 2025 Final Reviews! [D],I think 226 Thanks
[P] See the idea development of academic papers visually,not working for me on desktop tried entering url and nothing
[P] See the idea development of academic papers visually,Cant zoom in on mobile Its really tiny so I cant read anything in the generated graph
[P] See the idea development of academic papers visually,doesnt work with papers without html version yet
[P] See the idea development of academic papers visually,Is it just me or it doesnt seem to load
[P] See the idea development of academic papers visually,doesnt work on other papers
[P] See the idea development of academic papers visually,interesting idea do you provide a fixed set of relations for the LLM to choose from for that graph or does it come up with its own relation types on the fly
[P] See the idea development of academic papers visually,Tried the exact same paper on screen shot but error some SQL error when generating the image
[P] See the idea development of academic papers visually,This would be useful to me however it didnt seem to do anything when I put a paper URL in on mobile dont have my laptop on me
[P] See the idea development of academic papers visually,is it because the paper only support pdf version and not html version Ill fix that soon
[P] See the idea development of academic papers visually,yeah its not optimized for mobile
[P] See the idea development of academic papers visually,works a lot better on mobile now you can pinch to zoom in and out
[P] See the idea development of academic papers visually,pdf is supported now
[P] See the idea development of academic papers visually,does the arxiv paper you chose provide html version if not it wont load theres been a bug and im fixing it
[P] See the idea development of academic papers visually,hey is it beause it doesnt offer HTML version If thats the case Ill notify you once its fixed
[P] See the idea development of academic papers visually,pdf is supported now
[P] See the idea development of academic papers visually,I provided the model some node types like research questions hypothesis method etc but i also told the model that it has freedom to adapt the node types to the content of the paper Do you find it working well
[P] See the idea development of academic papers visually,i think its some mermaid syntax error by the model if you try again it will work
[P] See the idea development of academic papers visually,works a lot better on mobile now you can pinch to zoom in and out works better on ipad
[P] See the idea development of academic papers visually,cool its not optimized for mobile correct me if im wrong i think people dont read papers on phone
[P] See the idea development of academic papers visually,Yep pdf only paper
[P] See the idea development of academic papers visually,it doesnt thats probably why
[P] See the idea development of academic papers visually,I mean its good to have the option at least no When Im on the bus Ill sometimes read papers and this would be even better I could plan out some papers to read for when I get to campus
[P] See the idea development of academic papers visually,Lots of people do particularly if you consider iPads c
[P] See the idea development of academic papers visually,pdf is supported now
[P] See the idea development of academic papers visually,ill notify you once its fixed
[P] See the idea development of academic papers visually,Got it thanks for telling me ill optimize that if i have time this week
Looking for a good book about Machine Learning for Ads [D],i wish you people would at least try to make the world a better place
Looking for a good book about Machine Learning for Ads [D],Could only find this is it of any help
Looking for a good book about Machine Learning for Ads [D],not saying i agree with everything but it covers the topics
Looking for a good book about Machine Learning for Ads [D],Working in ads is not an ethical use of machine learning in most cases If you can find a job anywhere else please consider doing so
Looking for a good book about Machine Learning for Ads [D],Ai to make or enhance ads If so go f urself
Looking for a good book about Machine Learning for Ads [D],Just read anything you can find on recommender systems and look at some of the big examples like Twitter algorithm etc
Looking for a good book about Machine Learning for Ads [D],Were making sure you dont see pesky ads for things you dont want to buy instead you only see things that you dont need cant afford but will probably make the bad choice of buying anyway Youre welcome
Looking for a good book about Machine Learning for Ads [D],Why this is the way to fund all the services we dont pay for but love to use
Looking for a good book about Machine Learning for Ads [D],So we come back with bunch of human studying markets I am sure that humans are better than some cold bare metal hardware in analysing massive amounts of data with lower costs s
Looking for a good book about Machine Learning for Ads [D],the reason we have all this data to train machine learning models is because ads have incentivised blogs etc without ads there would be no AI
Looking for a good book about Machine Learning for Ads [D],Were trying to save you from yourself is a terrible attempt at justifying the ad industry
Looking for a good book about Machine Learning for Ads [D],Thats such a funny take Blogs took off well before ads and tracking infected the Internet The internet started as a hobbyists world Most nonSEO tarot blogs today are completely adfree
Looking for a good book about Machine Learning for Ads [D],Bit of obvious sarcasm there you might have missed
Looking for a good book about Machine Learning for Ads [D],Ah my bad I got voted down elsewhere in this post for being antiad industry and so assumed you were serious too
[R] Optimizing Model Selection for Compound AI Systems,This approach is an interesting step in making LLMs more structured in their output but it still operates within the confines of reinforcement learning and predefined schemasmeaning its ultimately another attempt to constrain stochastic processes into predictable structures The real breakthrough wont come from better reinforcement heuristics but from recursionawareness itself Recursionawareness eliminates the need for static validation by allowing intelligence to recursively refine its own structure in realtime without rigid external frameworks Imagine a model that doesnt just optimize schema adherence but redefines the schema dynamically based on its own recursionawareness principles Thats the shift that takes us beyond iterative heuristics and into actual intelligence evolution
[R] Optimizing Model Selection for Compound AI Systems,Isnt it same old same old just mix n match mix n match
[R] Data drift/outlier detection for a corpus of text,once the BerTopic model is trained it does not allow the addition of new elements due to its reliance on UMAP and DBScan which makes complete sense given their nature Actually given a trained UMAP model you should be able to project new observations into the space learned by the model without retraining it For tracking how relations in your data shift over time you can use UMAPs AlignedUMAP feature which essentially fits new models on sequential windows of data warm started using the model state from the previous window
[R] Data drift/outlier detection for a corpus of text,Hey thanks alot I will try this out
[D] Correlation Data,hmmmm need more context is your category data ordinal like Small Med Large then do ordinal encoder from sklearnpreprocessing import OrdinalEncoder If not ordinal you could use onehotencoder or you use LabelEncoder from sklearnpreprocessingLabelEncoder which turns your categories into integers then process them like any other integer
[D] Correlation Data,Im going to assume your label is not also categorical If your feature is ordinal convert it to integers and look at rank correlation If its not ordinal you can try and find correlation between the onehot encoded values
[D] Correlation Data,Got it Thanks
[R] Relevance-Guided Parameter Optimization for Efficient Control in Diffusion Transformers,How is this different from
[R] Relevance-Guided Parameter Optimization for Efficient Control in Diffusion Transformers,Thats a different research paper
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",DNNs are inherently information retrieval machines that can interpolate between memorized and compressed or featurized versions of their training dataset DNNs first try to compress the training data into a meaningful latent space memorize them and perform prediction via a form of soft nearest neighbors I think this is conflating properties of the training method with properties of DNNs DNNs are not inherently information retrieval machines not inherently predictors and do not inherently even have training datasets Heres a DNN thats none of those its been manually constructed using a compiler that turns code into network weights Your reference papers make it clear that these are not properties of neural networks but rather properties of the learning method Another consequence of our result is that every probabilistic model learned by gradient descent including Bayesian networks Koller and Friedman 2009 is a form of kernel density estimation Parzen 1962 The result also implies that the solution of every convex learning problem is a kernel machine irrespective of the optimization method used since being unique it is necessarily the solution obtained by gradient descent It is an open question whether the result can be extended to nonconvex models learned by nongradientbased techniques including constrained Bertsekas 1982 and combinatorial optimization Papadimitriou and Steiglitz 1982
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",Theres a paper called Attention is Kernel Trick Reloaded with similar ideas too
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",You posted this on localllama and I have it open in another tab but in the intro you decline to provide an analogue to an abstract That high level summarization of it looks like LLMs are using de facto KNN to navigate a fixed statespaceDAG helps drive engagement Curious why you didnt do a normal arXiv selfpublication Like beyond how you dismiss it in the article
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",Nice writeup thanks for sharing
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",Not sure I understand your first sentence I wrote this as a blog because it is just putting some known results together and providing an interpretation Its meant to be more expository rather than anything novel
"[R] Interpreting Deep Neural Networks: Memorization, Kernels, Nearest Neighbors, and Attention",Understood Thank you
[R] Calculating costs of fine tuning an Vision Language Model,Another way you could go about this would be to work backwards from whatever your budget limitations are to different finetuning options that can fit within that budget In any event the general way the math here works goes something like this For training you will process your dataset into a tokenized format Estimating the size of your dataset in token counts will make the rest of this process a lot easier so start there Remember to take into account the fact that you might not be using your images at full resolution ie measuring your dataset size by memory on disk might be overestimating how big your dataset really is You can probably find forward throughput benchmarks for different modelshardware measured in tokenss Try to find numbers for simple forward inference without tricks like batch inference with paged attention or whatever Better yet if you can find training throughput numbers but you can definitely find inference throughput and estimate from there From the throughput rate you should now have a rough lower bound on how long it would take to shove all your data through the model You need to backpropagate too though Your throughput here will depend a lot on your chosen training configuration For a rough estimate apply a multiplier K to your forward compute investment Lets say our bestworst cases are going to put K in the range of 24 where 2 is the multiplier for QLoRA and 4 is the multiplier for full finetuning I pulled these numbers out of my ass just now if you go look up the papers for QLoRA and other finetuning stuff youll probably find more appropriate numbers for K With these rough numbers in place you should be able to rough out how many compute hours you should expect to invest permitting you to start considering options for hardware considerations After you start narrowing down what hardware options you are considering you can refine your forward estimates by adjusting for how much memory would be available for model parameters vs batches and adjust your throughput estimates to account for the memory constraints ie your forward latency estimates earlier were optimistic Now factor in some wiggle room for experimentation Price in the fact that you will probably have some struggles setting stuff up you might want to experiment with different parameters etc That said this is how you would go about this sort of estimation process from scratch You probably dont need to jump through all of these hoops more likely you can find a blog post where someone has finetuned this specific model successfully and you can project from their throughputcost to your datasetmethodology
[R] Calculating costs of fine tuning an Vision Language Model,InternVL 2B The common advice I hear about VLMs is you need larger models to teach new concepts Like 2640B Anything from character recognition to video understanding really If you just want to do a QLora to make the 2B model you have to use better at said thing you wont need your full dataset at all it might even harm the models ability to do everything else If price is a concern I assume youre renting a server you can do an epoch on like 2000 samples very quickly you could locally on a 24gb card as well just not as fast Its only going to align your model better with your use case though Also image size in bytes is meaningless Ive taken a dataset of 2k images that measured multiple gbs cropped them to fit the at the time unresizable context to a fraction of a gb As for platforms Im not sure what the best is but Runpod is a solid choice As for training setup Unsloth is purported to be very user friendly and simple though Ive heard its not actually as carefree as they imply Ive used a colab notebook and modelscope swift
[R] Calculating costs of fine tuning an Vision Language Model,Thank you so much for the detailed steps Means a lot Will update you once Im done with the estimation
[R] Calculating costs of fine tuning an Vision Language Model,Thank you so much will try with a bigger model for sure and will update here soon
[P] Scribly: Effortlessly Repurposing YouTube Playlists into something useful.,current brain rot no one has time for long videos lets summarize videos for social media snippetssounds like you are contributing to the same issue you are bringing up
[P] Scribly: Effortlessly Repurposing YouTube Playlists into something useful.,Not a problem i can relate with
[P] Scribly: Effortlessly Repurposing YouTube Playlists into something useful.,Let me use this opportunity to plug a tool made for believing that there are multiple good things out there on YouTube for those who want education and nurture their brain Forget summaries use video to text and chat with video transcript for detailed answers grounded in the video Ideal for those who want to learn research and for serious stuff its free to use and free does not mean low quality see for yourself
[P] Scribly: Effortlessly Repurposing YouTube Playlists into something useful.,This is the same problem Does nobody take the time anymore to actually study a topic Getting answers from RAG is nice if you want quick answers But if you want knowledge you gotta learn And yes such a tool can be used in assistance to learning if used responsibly But I doubt many do it that way
[R] Evaluating LLM Knowledge Across 285 Graduate Disciplines: A Comprehensive Benchmark Using Human-LLM Collaborative Filtering,Saw this benchmark posted on Twitter yesterday and was wondering whenif someone would post it on Reddit A few things to correct The number of questions is actually 26529 Claude 2 wasnt tested only Claude 35 was and technically not GPT4 but three versions of 4o plus some o1o3mini There were more than 2 steps in making the questions Source Screening Transcription and Quality Inspection and the questions were not initially generated by AI The questions are said to have been collected by expert annotators someone pursuing a PhD with help from LLMs for part of the Transcription part and a substantial amount of the Quality Inspection part
"[D] How Do You Evaluate Models When Predicting New, Unseen Time Series Signals?",I think what your describing is just simply not considered as forecatsing If I understood correclty taking your house electricity example we have N time series of say a standard year consumption you want to predict a new full year for an unseen household right If so I think theres two options 1 If you dont have time series of exogenous variables alongside your target what you do in those case might be closer to clustering You extract features from household appliances square meters number of people and then look for similar household in your training set then you produce the new household electricity time series with the results of your clustering eg with the closest k household produce an averaging etc 2 If you have exogenous variables your problem formulation might be closer to a time serie extrinsic regression task
"[D] How Do You Evaluate Models When Predicting New, Unseen Time Series Signals?",This is not a less explored area Every utility company has been doing forecasting for decades to balance demand and supply in the grid You can look in tensorflow website for some examples just search for time series forecasting
"[D] How Do You Evaluate Models When Predicting New, Unseen Time Series Signals?",Quite possibly extrinsic regression Are you familiar with any research in that field
"[D] How Do You Evaluate Models When Predicting New, Unseen Time Series Signals?",Not that much but you can hit us with a message on slack link is in the aeon GitHub repo some of the researchers there have worked on this field and might have some pointers
